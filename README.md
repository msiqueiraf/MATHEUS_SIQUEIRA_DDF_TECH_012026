# Case T√©cnico Dadosfera - Analista de Dados

**Candidato:** Matheus Siqueira  
**Data:** Janeiro/2026  
**Reposit√≥rio:** MATHEUS_SIQUEIRA_DDF_TECH_012026  

---

## üìã Item 0: Agilidade e Planejamento

Utilizei uma abordagem √Ågil (Kanban) para organizar as entregas deste case, priorizando a infraestrutura de dados (Bronze/Silver) antes da camada de intelig√™ncia e visualiza√ß√£o (Gold).

### üìÖ Status do Projeto

#### ‚úÖ Done (Conclu√≠do)
- [x] **Item 0:** Planejamento e Arquitetura
- [x] **Item 1:** Sele√ß√£o do Dataset (Brazilian E-Commerce Olist)
- [x] **Item 2:** Ingest√£o de Dados na Plataforma Dadosfera
- [x] **Item 3:** Cataloga√ß√£o e Dicion√°rio de Dados
- [x] **Item 4:** Valida√ß√£o de Qualidade de Dados (Great Expectations)
- [x] **Item 5:** Enriquecimento com IA (Feature Engineering / NLP)
- [x] **Item 6:** Modelagem Dimensional (Star Schema)
- [x] **Item 7:** Dashboard Anal√≠tico (Power BI)
- [x] **Item 8:** Orquestra√ß√£o de Pipelines (ETL)
- [x] **Item 9:** Data App Interativo (Streamlit)

#### üìπ To Do (A Fazer)
- [ ] **Item 10:** Grava√ß√£o do V√≠deo de Apresenta√ß√£o (Storytelling)

---

## üíæ Item 1: Sobre a Base de Dados

Para simular um cen√°rio real de **E-commerce Brasileiro** com alta complexidade e volume (>100k registros), selecionei o **Brazilian E-Commerce Public Dataset by Olist**.

* **Motivo da Escolha:** O dataset oferece dados relacionais ricos (pedidos, clientes, produtos, geolocaliza√ß√£o) e dados desestruturados (reviews em texto), permitindo explorar todo o ciclo de vida dos dados exigido no case.
* **Volume:** A tabela principal `order_items` possui mais de 112.000 registros, atendendo ao requisito m√≠nimo do case.

---

## üîå Item 2 & 3: Integra√ß√£o e Explora√ß√£o (Dadosfera)

Realizei a ingest√£o dos arquivos CSV brutos para a camada de **Coleta** da Dadosfera. Os dados foram catalogados com descri√ß√µes funcionais e t√©cnicas para facilitar o self-service analytics por usu√°rios de neg√≥cio.

> üìò **Documenta√ß√£o T√©cnica:** Para detalhes aprofundados sobre a linhagem, tipagem e regras de neg√≥cio aplicadas em cada tabela (Silver/Gold), consulte o **[Dicion√°rio de Dados T√©cnico](./DATA_DICTIONARY.md)**.

**Evid√™ncia da Carga e Cataloga√ß√£o na Plataforma:**

![Print da Dadosfera - Ingest√£o](assets/item23_coleta_dadosfera.png)

---

## üïµÔ∏è Item 4: Data Quality (Observabilidade)

Implementei um pipeline de auditoria automatizada fundamentado em **Data Contracts** e observabilidade de dados. Utilizei uma l√≥gica de valida√ß√£o inspirada no framework *Great Expectations* para garantir que apenas dados √≠ntegros e confi√°veis avancem para a camada de modelagem. Todo o motor de auditoria e monitoramento est√° centralizado no arquivo **`data_quality.py`** na raiz do reposit√≥rio.

**Regras de Auditoria Aplicadas:**
* **Consist√™ncia de Dom√≠nio:** Valida√ß√£o estat√≠stica rigorosa para garantir que a coluna `review_score` esteja dentro do intervalo esperado de **1 a 5**.
* **Integridade Referencial:** Check de completude na **Chave Prim√°ria** `review_id` (Zero Nulls), assegurando a unicidade e rastreabilidade total dos registros.
* **Health Check & Monitoring:** Gera√ß√£o autom√°tica de m√©tricas descritivas (M√≠nimo, M√°ximo e M√©dia) para monitoramento de sa√∫de da base e detec√ß√£o precoce de anomalias.

**Evid√™ncia do Relat√≥rio de Qualidade:**

![Relat√≥rio de Data Quality](assets/item4_data_quality.png)

---

## ü§ñ Item 5: Enriquecimento com IA (Advanced NLP no Power Query)

Para processar o volume de textos desestruturados (`review_comment_message`), desenvolvi um motor de **NLP** robusto utilizando a biblioteca **spaCy** (modelo `pt_core_news_sm`).

**Diferencial T√©cnico: Motor de Infer√™ncia H√≠brida**
Implementei uma **Calibra√ß√£o de Ground Truth**, onde o algoritmo correlaciona a sem√¢ntica extra√≠da via IA com a nota real deixada pelo cliente, calibrando a polaridade final para refletir a experi√™ncia real do usu√°rio.

**Integra√ß√£o e Portabilidade:**
A l√≥gica est√° encapsulada no script **`power_query_nlp.py`**. O c√≥digo foi portado para o ambiente do **Power Query (Python Step)**, permitindo o enriquecimento din√¢mico do modelo de dados diretamente no Power BI a cada refresh.

* **Otimiza√ß√£o Upstream:** Implementei uma filtragem pr√©via no Power Query para enviar ao script Python apenas as colunas estritamente necess√°rias (`id`, `score`, `text`), reduzindo o tempo de processamento e serializa√ß√£o de dados.
* **M√©tricas de Sa√≠da:** Gera√ß√£o das colunas `Polaridade_IA` (-1.0 a +1.0) e `Sentimento_IA` (Positivo üü¢ / Neutro üü° / Negativo üî¥).

**Evid√™ncia da Integra√ß√£o no Power BI:**

![Script Python no Power Query](assets/powerquery_python_integration.png)

**Evid√™ncia do Pipeline de NLP:**

![Output do Script de IA](assets/item5_nlp.png)

---

## üìê Item 6: Modelagem de Dados

Desenvolvi uma modelagem **Star Schema (Fato/Dimens√£o)** no Power BI para garantir alta performance nas consultas DAX e facilidade de uso para o usu√°rio final.

### üèóÔ∏è Engenharia de Dados e Performance (Silver Layer)
Apliquei conceitos avan√ßados de engenharia na etapa de transforma√ß√£o (Power Query) para garantir escalabilidade e governan√ßa:

1.  **Governan√ßa (Naming Conventions):** Adotei estritamente o padr√£o **`snake_case`** (ex: `product_category_name` em vez de `Nome da Categoria`) e removi acentos/caracteres especiais.
    * *Motivo:* Garantir interoperabilidade imediata caso o modelo seja migrado para Data Lakes (Parquet/Delta) ou Bancos SQL, onde espa√ßos e acentos costumam quebrar pipelines.
2.  **Vertical Partitioning (Performance):** Realizei a remo√ß√£o agressiva de colunas de alta cardinalidade n√£o utilizadas (ex: `product_description`) antes da carga.
    * *Impacto:* Redu√ß√£o dr√°stica do consumo de mem√≥ria do motor VertiPaq e acelera√ß√£o do refresh.
3.  **Type Safety & Localization:** Implementa√ß√£o de tratamento expl√≠cito de locale (`en-US`) na camada M.
    * *Motivo:* Garantir que pre√ßos e coordenadas geogr√°ficas vindos de CSVs internacionais (separador decimal ponto) sejam interpretados corretamente, evitando erros de magnitude financeira.
4.  **Data Enrichment (B√¥nus 2):** Enriquecimento da dimens√£o de clientes (`dCustomers`) com coordenadas exatas de **Latitude e Longitude**.
    * *T√©cnica:* Realizei o agrupamento (Group By) da base de geolocaliza√ß√£o (reduzindo 1MM+ linhas para chaves √∫nicas de CEP) antes de realizar o *Merge*, garantindo performance sem perder precis√£o geogr√°fica.

### Estrutura do Modelo
* **Tabela Fato (`fOrderItems`):** Cont√©m os dados transacionais (granularidade por item vendido).
    * *M√©tricas:* Valor de Venda, Valor de Frete, Quantidade.
* **Dimens√µes (`d...`):** Tabelas auxiliares que fornecem contexto descritivo.
    * `dProducts` (Categorias higienizadas e padronizadas).
    * `dOrders` (Status e datas do ciclo de vida do pedido).
    * `dCustomers` (Localiza√ß√£o geogr√°fica por Estado/Cidade).
    * `dReviews` (Coment√°rios e notas de satisfa√ß√£o enriquecidas via IA).

**Diagrama de Entidade-Relacionamento (DER):**

![Modelagem Star Schema](assets/item6_modelagem.png)

---

## üìä Item 7 & B√¥nus 3: An√°lise de Dados (Power BI & SQL)

Para cumprir o requisito de an√°lise explorat√≥ria e valida√ß√£o de categorias, utilizei o **SQL Lab** da Dadosfera (Engine Snowflake) antes de partir para a visualiza√ß√£o no Power BI.

### üîç Valida√ß√£o Explorat√≥ria (SQL)
**Objetivo:** Validar a distribui√ß√£o de produtos por categoria diretamente na fonte (Silver Layer), assegurando a integridade dos dados antes da modelagem.

**Evid√™ncia da Execu√ß√£o (Query + Resultado):**

![Resultado SQL](assets/item7_sql_query.png)

### üöÄ Dashboard Executivo (Power BI)
Desenvolvi um **Data App** no Power BI dividido em duas camadas estrat√©gicas, unindo Engenharia de Dados robusta com UX avan√ßado via HTML/SVG (DAX).

**Link para o Arquivo:** [Dashboard Power BI (.pbix)](./dashboard_analise_olist.pbix)

#### 1. Executive Insights (Vis√£o Macro/Estrat√©gica)
Focada no C-Level, consolidando a sa√∫de financeira e log√≠stica.
* **Header Din√¢mico:** Visualiza√ß√£o *Glassmorphism* com KPIs de Faturamento e Sentimento Geral.
* **Breakdown de Log√≠stica:** An√°lise de gargalos (Lead Time) separando Aprova√ß√£o, Separa√ß√£o e Last Mile.
* **Top 3 Categorias:** Ranking inteligente que cruza Receita com Percep√ß√£o do Cliente (IA Score).

![Executive Insights Dashboard](assets/item10_powerbi1.png)

#### 2. Operational Intelligence (Vis√£o Micro/T√°tica)
Focada em identificar ofensores, produtos cr√≠ticos e oportunidades geogr√°ficas.
* **Operational Header (Ranking em Tempo Real):** Identifica√ß√£o autom√°tica do "Best Seller", "Top Regi√£o" e "√Årea de Aten√ß√£o Cr√≠tica" (pior sentimento).
* **Product Deep Dive (Card 360¬∫):** Diagn√≥stico autom√°tico que cruza Vendas vs. Sentimento para classificar produtos (ex: "Risco de Churn" ou "Estrela de Vendas").
* **Geo-Intelligence:** Mapa de calor utilizando coordenadas exatas (Lat/Long) para identificar densidade de demanda.

![Operational Intelligence Dashboard](assets/item10_powerbi2.png)

#### Destaques T√©cnicos (S√™nior)
* **UX/UI Avan√ßado:** Substitui√ß√£o de cart√µes nativos por componentes HTML/CSS injetados via DAX para flexibilidade total de design.
* **Otimiza√ß√£o da Dimens√£o Tempo (`dTime`):** Tabela dimens√£o otimizada com granularidade de minutos para reduzir cardinalidade e melhorar performance do VertiPaq.
* **Gloss√°rio Integrado:** Implementa√ß√£o de Tooltips explicativas (Mini-manual) para garantir a governan√ßa e entendimento das m√©tricas de IA pelo usu√°rio final.

---

## üåä Item 8: Pipeline de Dados (Orquestra√ß√£o)

Para garantir a atualiza√ß√£o cont√≠nua e a governan√ßa dos dados, desenhei um pipeline de ingest√£o na Dadosfera que automatiza a coleta dos arquivos brutos (Raw Data).

**Fluxo Desenhado:**
1. **Coleta:** Leitura incremental de arquivos CSV em Bucket S3.
2. **Ingest√£o:** Carga para a Landing Zone da Dadosfera.
3. **Cataloga√ß√£o:** Registro autom√°tico de metadados t√©cnicos.
4. **Agendamento:** Execu√ß√£o di√°ria automatizada.

**Evid√™ncia do Pipeline Catalogado:**

![Pipeline Dadosfera](assets/item8_pipeline.png)

---

## üì± Item 9: Data App (Streamlit)

Desenvolvi uma aplica√ß√£o interativa utilizando o framework **Streamlit** (Python) para democratizar o acesso aos dados de satisfa√ß√£o. O app permite que gestores filtrem reviews por regi√£o e acompanhem KPIs em tempo real.

**Funcionalidades:**
* Filtros Din√¢micos de Regi√£o.
* Formata√ß√£o monet√°ria padr√£o BRL (R$).
* Comparativo de Metas (vs M√™s Anterior).
* Visualiza√ß√£o Dark Mode para alto contraste.

**Preview do App:**

![Data App Streamlit](assets/item9_data_app.png)

### üõ†Ô∏è Como Executar este Data App
O desenvolvimento foi realizado utilizando o **Google Colab**. Para reproduzir localmente:

1. **Pr√©-requisitos:** Python 3.9+, Streamlit, Pandas e Plotly.
2. **Instala√ß√£o:** `pip install streamlit pandas plotly`.
3. **Execu√ß√£o:** Navegue at√© a pasta do projeto e execute no terminal: `streamlit run app.py`.
4. **Acesso Remoto (Cloud):** Utilizado t√∫nel via **Ngrok** para deploy simulado durante o desenvolvimento.

---

## ‚è≠Ô∏è Pr√≥ximos Passos (Roadmap)
- Grava√ß√£o do v√≠deo de apresenta√ß√£o executiva (Item 10).
- Implementa√ß√£o de alertas autom√°ticos via Slack/Teams baseados na queda do NPS.
