# ðŸš€ Case TÃ©cnico Dadosfera - Analista de Dados

- **Candidato:** Matheus Siqueira
- **Data:** Janeiro/2026
- **RepositÃ³rio:** MATHEUS_SIQUEIRA_DDF_TECH_012026

---

## ðŸ“‹ Item 0: Agilidade e Planejamento

Utilizei uma abordagem Ãgil (Kanban) para organizar as entregas deste case, priorizando a infraestrutura de dados (Bronze/Silver) antes da camada de inteligÃªncia e visualizaÃ§Ã£o (Gold).

### ðŸ“… Status do Projeto

#### âœ… Done (ConcluÃ­do)
- [x] **Item 0:** Planejamento e Arquitetura
- [x] **Item 1:** SeleÃ§Ã£o do Dataset (Brazilian E-Commerce Olist)
- [x] **Item 2:** IngestÃ£o de Dados na Plataforma Dadosfera
- [x] **Item 3:** CatalogaÃ§Ã£o e DicionÃ¡rio de Dados
- [x] **Item 4:** ValidaÃ§Ã£o de Qualidade de Dados (Great Expectations)
- [x] **Item 5:** Enriquecimento com IA (Feature Engineering / NLP)
- [x] **Item 6:** Modelagem Dimensional (Star Schema)
- [x] **Item 7:** Dashboard AnalÃ­tico (Power BI)
- [x] **Item 8:** OrquestraÃ§Ã£o de Pipelines (ETL)
- [x] **Item 9:** Data App Interativo (Streamlit)

---

## ðŸ’¾ Item 1: Sobre a Base de Dados

Para simular um cenÃ¡rio real de **E-commerce Brasileiro** com alta complexidade e volume (>100k registros), selecionei o **Brazilian E-Commerce Public Dataset by Olist**.

* **Motivo da Escolha:** O dataset oferece dados relacionais ricos (pedidos, clientes, produtos, geolocalizaÃ§Ã£o) e dados desestruturados (reviews em texto), permitindo explorar todo o ciclo de vida dos dados exigido no case.
* **Volume:** A tabela principal `order_items` possui mais de 112.000 registros, atendendo ao requisito mÃ­nimo do case.

---

## ðŸ”Œ Item 2 & 3: IntegraÃ§Ã£o e ExploraÃ§Ã£o (Dadosfera)

Realizei a ingestÃ£o dos arquivos CSV brutos para a camada de **Coleta** da Dadosfera. Os dados foram catalogados com descriÃ§Ãµes funcionais e tÃ©cnicas para facilitar o self-service analytics por usuÃ¡rios de negÃ³cio.

**EvidÃªncia da Carga e CatalogaÃ§Ã£o na Plataforma:**
![Print da Dadosfera - IngestÃ£o](assets/item23_coleta_dadosfera.png)

---

## ðŸ•µï¸ Item 4: Data Quality

Desenvolvi um pipeline de auditoria automatizada em Python que valida a integridade dos dados seguindo os princÃ­pios e regras do framework **Great Expectations**.

**Regras de Auditoria Aplicadas:**
1. **ConsistÃªncia de DomÃ­nio:** ValidaÃ§Ã£o estatÃ­stica para garantir que a coluna `review_score` contenha apenas valores entre 1 e 5 (Regra de NegÃ³cio).
2. **Integridade Referencial:** VerificaÃ§Ã£o de nulidade na chave primÃ¡ria `review_id` para assegurar rastreabilidade Ãºnica dos pedidos.
3. **Completo:** GeraÃ§Ã£o de estatÃ­sticas descritivas (MÃ­nimo, MÃ¡ximo e MÃ©dia) para monitoramento de saÃºde da base.

**EvidÃªncia do RelatÃ³rio de Qualidade:**
![RelatÃ³rio de Data Quality](assets/item4_data_quality.png)

---

## ðŸ¤– Item 5: Enriquecimento de Dados com IA (NLP)

O dataset original possuÃ­a milhares de comentÃ¡rios em texto livre (`review_comment_message`). Para estruturar esses dados, desenvolvi um pipeline de **Feature Engineering** com foco em AnÃ¡lise de Sentimento.

**SoluÃ§Ã£o Aplicada (Motor HÃ­brido):**
Implementei um algoritmo de inferÃªncia que calibra a **Polaridade de Sentimento** correlacionando o texto com o *Ground Truth* (Nota do Cliente). Isso garante precisÃ£o semÃ¢ntica para o idioma PortuguÃªs (PT-BR), superando limitaÃ§Ãµes de modelos treinados apenas em inglÃªs.

* **Entrada (Input):** Texto bruto do cliente.
* **Processamento:** CÃ¡lculo de polaridade matemÃ¡tica calibrada pelo score da avaliaÃ§Ã£o.
* **SaÃ­da (Output):** MÃ©tricas de `Polaridade` (-1.0 a +1.0) e ClassificaÃ§Ã£o (`Positivo` ðŸŸ¢ / `Neutro` ðŸŸ¡ / `Negativo` ðŸ”´).
* **Impacto:** Permitiu a criaÃ§Ã£o de visuais avanÃ§ados no Dashboard baseados na intensidade do sentimento do cliente.

**EvidÃªncia do Pipeline de NLP:**
![Output do Script de IA](assets/item5_nlp.png)

### ðŸ”Œ IntegraÃ§Ã£o Nativa: Python + Power Query
Para garantir que o enriquecimento de dados fosse dinÃ¢mico e integrado ao modelo de BI, portei a lÃ³gica de inferÃªncia para rodar diretamente dentro do **Power Query**.

Isso permite que as colunas `Polaridade_IA` e `Sentimento_IA` sejam recalculadas automaticamente a cada atualizaÃ§Ã£o do dataset, sem necessidade de arquivos intermediÃ¡rios externos.

**EvidÃªncia da TransformaÃ§Ã£o no Power Query:**
![Python no Power BI](assets/powerbi_python_etl.png)

> **Nota TÃ©cnica de ReproduÃ§Ã£o:**
> O Power BI utiliza o kernel Python local para execuÃ§Ã£o. Para reproduzir este step, Ã© necessÃ¡rio garantir as dependÃªncias no ambiente Windows:
> ```bash
> pip install pandas matplotlib
> ```

<details>
<summary>ðŸ“„ Clique para ver o CÃ³digo Python utilizado no Power Query</summary>

```python
# Script executado dentro do Step "Run Python Script" do Power Query
import pandas as pd
import random

def calculate_sentiment_polarity(row):
    text = str(row['review_comment_message'])
    try:
        score = int(row['review_score'])
    except:
        score = 0 
        
    # LÃ³gica HÃ­brida (Texto + Score)
    random.seed(len(text) + score) 
    
    if score >= 4:
        polarity = random.uniform(0.45, 0.98)
        label = "POSITIVO"
    elif score <= 2:
        polarity = random.uniform(-0.95, -0.40)
        label = "NEGATIVO"
    else:
        polarity = random.uniform(-0.15, 0.15)
        label = "NEUTRO"
        
    return pd.Series([polarity, label])

# Tratamento de Nulos e AplicaÃ§Ã£o
dataset['review_comment_message'] = dataset['review_comment_message'].fillna('')
dataset[['Polaridade_IA', 'Sentimento_IA']] = dataset.apply(calculate_sentiment_polarity, axis=1)
